{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anush\\anaconda3\\envs\\mleng\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A completely empty class\n",
    "class StepByStep(object): \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor : Define parts(attributes) that make up the class  \n",
    "\n",
    " Typical attributes include:\n",
    " * arguments provided by user\n",
    " * placehlders for other objects that are currently unavailable\n",
    " * variables that needed be tracked of\n",
    " * functions that are dynamically built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    def __init__(self,model,loss_fn,optimizer):\n",
    "        # Here we use define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use later\n",
    "        self.model=model\n",
    "        self.loss_fn=loss_fn\n",
    "        self.optimizer=optimizer\n",
    "        self.device='cuda' if torch.cuda.is_aviailable() else 'cpu'\n",
    "        # lets send the model to the device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def to(self,device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets corresponding attribute and sends the model to device\n",
    "        try:\n",
    "            self.device=device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError: # runtime error is raised if the device is not avilaible\n",
    "            self.device=('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldnt send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Placeholders/delayed arguments\n",
    "ex: Train and val loaders, summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    # constructor\n",
    "    def __init__(self,model,loss_fn,optimizer):\n",
    "        # Here we use define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use later\n",
    "        self.model=model\n",
    "        self.loss_fn=loss_fn\n",
    "        self.optimizer=optimizer\n",
    "        self.device='cuda' if torch.cuda.is_aviailable() else 'cpu'\n",
    "        # Placeholders\n",
    "        self.train_loader=None\n",
    "        self.val_loader=None\n",
    "        self.writer=None\n",
    "        # lets send the model to the device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def to(self,device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets corresponding attribute and sends the model to device\n",
    "        try:\n",
    "            self.device=device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError: # runtime error is raised if the device is not avilaible\n",
    "            self.device=('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldnt send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self,train_loader,val_loader=None):\n",
    "        # This method allows the user to specify the which loader to use\n",
    "        # Both loaders are then assign to corresponding attributes\n",
    "        self.train_loader=train_loader\n",
    "        self.val_loader=val_loader\n",
    "\n",
    "    def set_tensorboard(self,name,folder='runs'):\n",
    "        # This method allows the user to create a summarywriter to interface with tensorboard.\n",
    "        suffix=datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer=SummaryWriter(f\"{folder}/{name}_{suffix}\")\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Variables  \n",
    "### 4. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    # constructor\n",
    "    def __init__(self,model,loss_fn,optimizer):\n",
    "        # Here we use define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use later\n",
    "        self.model=model\n",
    "        self.loss_fn=loss_fn\n",
    "        self.optimizer=optimizer\n",
    "        self.device='cuda' if torch.cuda.is_aviailable() else 'cpu'\n",
    "        # Placeholders\n",
    "        self.train_loader=None\n",
    "        self.val_loader=None\n",
    "        self.writer=None\n",
    "        # variables that needs to be keep track of\n",
    "        self.losses=[]\n",
    "        self.val_losses=[]\n",
    "        self.total_epochs=0\n",
    "        # create  train step function for model, loss function and optimizer\n",
    "        self.train_step_fn=self._make_train_step_fn() # There are no arguments. It make use of class attributes directly\n",
    "        # create validation step function for model and loss function\n",
    "        self.val_step_fn=self._make_val_step_fn()\n",
    "        # lets send the model to the device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def to(self,device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets corresponding attribute and sends the model to device\n",
    "        try:\n",
    "            self.device=device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError: # runtime error is raised if the device is not avilaible\n",
    "            self.device=('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldnt send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self,train_loader,val_loader=None):\n",
    "        # This method allows the user to specify the which loader to use\n",
    "        # Both loaders are then assign to corresponding attributes\n",
    "        self.train_loader=train_loader\n",
    "        self.val_loader=val_loader\n",
    "\n",
    "    def set_tensorboard(self,name,folder='runs'):\n",
    "        # This method allows the user to create a summarywriter to interface with tensorboard.\n",
    "        suffix=datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer=SummaryWriter(f\"{folder}/{name}_{suffix}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepByStep(object):\n",
    "    # constructor\n",
    "    def __init__(self,model,loss_fn,optimizer):\n",
    "        # Here we use define the attributes of our class\n",
    "        # We start by storing the arguments as attributes to use later\n",
    "        self.model=model\n",
    "        self.loss_fn=loss_fn\n",
    "        self.optimizer=optimizer\n",
    "        self.device='cuda' if torch.cuda.is_aviailable() else 'cpu'\n",
    "        # Placeholders\n",
    "        self.train_loader=None\n",
    "        self.val_loader=None\n",
    "        self.writer=None\n",
    "        # variables that needs to be keep track of\n",
    "        self.losses=[]\n",
    "        self.val_losses=[]\n",
    "        self.total_epochs=0\n",
    "        # create  train step function for model, loss function and optimizer\n",
    "        self.train_step_fn=self._make_train_step_fn() # There are no arguments. It make use of class attributes directly\n",
    "        # create validation step function for model and loss function\n",
    "        self.val_step_fn=self._make_val_step_fn()\n",
    "        # lets send the model to the device\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def to(self,device):\n",
    "        # This method allows the user to specify a different device\n",
    "        # It sets corresponding attribute and sends the model to device\n",
    "        try:\n",
    "            self.device=device\n",
    "            self.model.to(self.device)\n",
    "        except RuntimeError: # runtime error is raised if the device is not avilaible\n",
    "            self.device=('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            print(f\"Couldnt send it to {device}, sending it to {self.device} instead\")\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def set_loaders(self,train_loader,val_loader=None):\n",
    "        # This method allows the user to specify the which loader to use\n",
    "        # Both loaders are then assign to corresponding attributes\n",
    "        self.train_loader=train_loader\n",
    "        self.val_loader=val_loader\n",
    "\n",
    "    def set_tensorboard(self,name,folder='runs'):\n",
    "        # This method allows the user to create a summarywriter to interface with tensorboard.\n",
    "        suffix=datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        self.writer=SummaryWriter(f\"{folder}/{name}_{suffix}\")\n",
    "\n",
    "    def _make_train_step_fn(self):\n",
    "        # This method is a closure that makes the train_step-function. closure is a function that returns a function\n",
    "        # it can directly use the class attributes\n",
    "        def perform_train_step_fn(x,y):\n",
    "            # set model to train mode\n",
    "            self.model.train()\n",
    "            # compute models prediction\n",
    "            yhat=self.model(x)\n",
    "            # compute the loss\n",
    "            loss=self.loss_fn(y,yhat)\n",
    "            # compute gradients\n",
    "            loss.backward()\n",
    "            # Update parameters\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Return the loss\n",
    "            return loss.item()\n",
    "        return perform_train_step_fn\n",
    "    \n",
    "    def _make_val_step_fn(self): # we use self here since we need to access class attributes\n",
    "        def perform_val_step_fn(x,y):\n",
    "            # set model to eval mode\n",
    "            self.model.eval()\n",
    "            # forward pass\n",
    "            yhat=self.model(x)\n",
    "            # compute loss\n",
    "            loss=self.loss_fn(yhat,y)\n",
    "            # since we dont update paramaters, no need to backprop\n",
    "            return loss.item()\n",
    "        return perform_val_step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`    METHODS`: Public  \n",
    "`    _METHODS`: Protected; supposed to be called either internally or child class  \n",
    "`    __METHODS`: Private; supposed to be called exclusively internally  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_make_train_step_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# using SETATTR for educational purposes only\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28msetattr\u001b[39m(StepByStep,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_make_train_step_fn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43m_make_train_step_fn\u001b[49m) \u001b[38;5;66;03m# setattr is used to add attributes to a class\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28msetattr\u001b[39m(StepByStep,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_make_val_step_fn\u001b[39m\u001b[38;5;124m'\u001b[39m,_make_val_step_fn)\n",
      "\u001b[1;31mNameError\u001b[0m: name '_make_train_step_fn' is not defined"
     ]
    }
   ],
   "source": [
    "# using SETATTR for educational purposes only\n",
    "setattr(StepByStep,'_make_train_step_fn',_make_train_step_fn) # setattr is used to add attributes to a class\n",
    "setattr(StepByStep,'_make_val_step_fn',_make_val_step_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog(object):\n",
    "    def __init__(self,name):\n",
    "        self.name=name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex\n"
     ]
    }
   ],
   "source": [
    "rex=Dog('Rex')\n",
    "print(rex.name)\n",
    "\n",
    "# rex is an instance of Dog class. instnace is an object of a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bark(dog): # bark function takes a dog object as an argument\n",
    "    print(f\"{dog.name} barks!: Woof!\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex barks!: Woof!\n"
     ]
    }
   ],
   "source": [
    "bark(rex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want bark function to be a method of Dog class\n",
    "def bark(self):\n",
    "    print(f\"{self.name} barks!: Woof!\")\n",
    "\n",
    "setattr(Dog,'bark',bark) # we add bark function to Dog class, setattr is used to add attributes to a class. Method is also  an attribute, so we can add methods to a class using setattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fido barks!: Woof!\n"
     ]
    }
   ],
   "source": [
    "fido=Dog('Fido')\n",
    "fido.bark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rex barks!: Woof!\n"
     ]
    }
   ],
   "source": [
    "rex.bark()\n",
    "# we effectively modified the underlying Dog class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_length(self):\n",
    "    return len(self.name)\n",
    "setattr(Dog,'NameLength',get_name_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rex.NameLength()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mini_batch(self,validation=False):\n",
    "    # mini batch function can be used with both loaders\n",
    "    # The argument validation is used to determine which loader to use\n",
    "    if validation:\n",
    "        data_loader=self.val_loader\n",
    "        step_fn=self.val_step_fn\n",
    "    else:\n",
    "        data_loader=self.train_loader\n",
    "        step_fn=self.train_step_fn\n",
    "\n",
    "    if data_loader is None:\n",
    "        return None\n",
    "    \n",
    "    # Once the data loader and setp function are set, we can use same mini batch loop that we used earlier\n",
    "    mini_batch_losses=[]\n",
    "    for X_batch, y_batch in data_loader:\n",
    "        X_batch=X_batch.to(self.device)\n",
    "        y_batch=y_batch.to(self.device)\n",
    "\n",
    "        mini_batch_loss=step_fn(X_batch,y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "    loss=np.mean(mini_batch_losses)\n",
    "    return loss\n",
    "\n",
    "setattr(StepByStep,'_mini_batch',_mini_batch) # setattr take 3 arguments; class name, attribute name and the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(self,seed=42):\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False \n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "setattr(StepByStep,'set_seed',set_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(self,n_epochs,seed=42):\n",
    "    # to ensure the reproducilbility of the training process\n",
    "    self.set_seed(seed)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # keep track of the number of epochs\n",
    "        self.total_epochs+=1\n",
    "\n",
    "        # inner loop\n",
    "        loss=self._mini_batch(validation=False)\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        # validation\n",
    "        # No grads in validation\n",
    "        with torch.no_grad():\n",
    "            val_loss=self._mini_batch(validation=True)\n",
    "            self.val_losses.append(val_loss)\n",
    "\n",
    "        # If a SummaryWriter is set,\n",
    "            if self.writer:\n",
    "                scalars={'training':loss} # Record the training loss\n",
    "                if val_loss is not None:\n",
    "                    scalars.update({'validation':val_loss})\n",
    "                # Record both losses for each epoch under tag 'loss'\n",
    "                self.writer.add_scalars(main_tag='loss',tag_scalar_dict=scalars,global_step=epoch)\n",
    "\n",
    "    if self.writer:\n",
    "        # flushes the writer\n",
    "        self.writer.flush # writer will write everything to disk\n",
    "    \n",
    "setattr(StepByStep,'train',train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving checkpoints; checkponit is a snapshot of the model at  a given time\n",
    "def save_checkpoint(self,filename):\n",
    "    # Build a dictionary with all the elements for resume training\n",
    "    checkpoint={'epoch':self.total_epochs,\n",
    "                'model_state_dict':self.model.state_dict(),\n",
    "                'optimizer_state_dict':self.optimizer.state_dict(),\n",
    "                'loss':self.losses,\n",
    "                'val_loss':self.val_losses}\n",
    "    torch.save(checkpoint,filename)\n",
    "\n",
    "setattr(StepByStep,'save_checkpoint',save_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading\n",
    "def load_checkpoint(self,filename):\n",
    "    checkpoint=torch.load(filename)\n",
    "    # Restore state for the model and optimizer\n",
    "    self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    self.total_epochs=checkpoint['epoch']\n",
    "    self.losses=checkpoint['loss']\n",
    "    self.val_losses=checkpoint['val_loss']\n",
    "    self.model.train() # always use TRAIN for Resume training \n",
    "\n",
    "setattr(StepByStep,'load_checkpoint',load_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions\n",
    "def predict(self,x):\n",
    "    # set the model to evaluation mode\n",
    "    self.model.eval()\n",
    "    # take a numpy input and make a float tensor\n",
    "    x_tensor=torch.as_tensor(x).float()\n",
    "    # send inpur to device and use model for prediction\n",
    "    y_hat_tensor=self.model(x_tensor.to(self.device))\n",
    "    # set model back to train mode because we are done with prediction\n",
    "    self.model.train()\n",
    "    # return the predictions as numpy array\n",
    "    return y_hat_tensor.detach().cpu().numpy() # detch is used to remove the tensor from the computational graph. computational graph: a way to keep track of the operations that are performed on the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mleng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
