{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "N=100\n",
    "true_w=2\n",
    "true_b=1\n",
    "np.random.seed(42) \n",
    "epsilon=0.1*np.random.randn(N,1)\n",
    "x=np.random.randn(N,1)\n",
    "y=true_w*x+true_b+epsilon\n",
    "\n",
    "idx=np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "train_idx=idx[:int(N*0.8)]\n",
    "valid_idx=idx[int(N*0.8):]\n",
    "\n",
    "X_train,y_train=x[train_idx],y[train_idx]\n",
    "X_valid,y_valid=x[valid_idx],y[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1382643] [0.49671415]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4397bc25d02b4d3083ac7d9f63126f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: 0.9953649757559992,\tw: 1.9849522275624543\n"
     ]
    }
   ],
   "source": [
    "# step 0: Random nitiation of parameters\n",
    "np.random.seed(42)\n",
    "w=np.random.randn(1)\n",
    "b=np.random.randn(1)\n",
    "\n",
    "print(b,w)\n",
    "\n",
    "# Initialization of Hyperparameters\n",
    "lr=0.1\n",
    "n_epochs=100\n",
    "# step 1: Forward pass\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    y_hat=w*X_train+b\n",
    "\n",
    "# step 2: Computing Loss \n",
    "    loss=np.mean(np.square(y_train-y_hat))\n",
    "    \n",
    "# step 3: Computing Gradient\n",
    "    b_grad=2*np.mean(y_hat-y_train)\n",
    "    w_grad=2*np.mean(X_train*(y_hat-y_train))\n",
    "\n",
    "# step 4: Updating Parameters\n",
    "    b=b-lr*b_grad\n",
    "    w=w-lr*w_grad\n",
    "\n",
    "\n",
    "print(f\"b: {b[0]},\\tw: {w[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:0.9953649899692825, \tw:1.9849523172037076\n"
     ]
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "print(f\"b:{model.intercept_[0]}, \\tw:{model.coef_[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar: 3.141590118408203,\n",
      "vector: tensor([1, 2, 3]),\n",
      "matrix: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]),\n",
      "tensor: tensor([[[-0.1044, -0.0098, -0.4790],\n",
      "         [ 2.1484,  1.7330,  1.0709]],\n",
      "\n",
      "        [[-1.3601,  0.7459,  0.6806],\n",
      "         [ 0.3519,  0.1171, -2.0195]]])\n"
     ]
    }
   ],
   "source": [
    "scalar=torch.tensor(3.14159)\n",
    "vector=torch.tensor([1,2,3])\n",
    "matrix=torch.ones((2,3))\n",
    "tensor=torch.randn((2,2,3),dtype=torch.float32) # 2 2x3 tensors\n",
    "\n",
    "print(f\"scalar: {scalar},\\nvector: {vector},\\nmatrix: {matrix},\\ntensor: {tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# shape of a tensor\n",
    "print(tensor.shape, tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([]), torch.Size([]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.size(),scalar.shape # scalars have empty shape beacuse they are dimensionless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `view()` method returns a shape with desired shape that shares underlying data of original tensor  \n",
    "* `reshape()` method may or may not create a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 5., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "tensor([[1., 5., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "same_matrix=matrix.view(1,6)\n",
    "same_matrix[0,1]=5\n",
    "\n",
    "print(f\"{matrix}\\n\\n{same_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`new_tensor()`, `clone()` ---> duplicate data in memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 5., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "tensor([[1., 7., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anush\\AppData\\Local\\Temp\\ipykernel_9684\\1908394546.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  different_matrix=matrix.new_tensor(matrix.view(1,6))\n"
     ]
    }
   ],
   "source": [
    "# copy the tensor to new one\n",
    "different_matrix=matrix.new_tensor(matrix.view(1,6))\n",
    "different_matrix[0,1]=7\n",
    "\n",
    "print(f\"{matrix}\\n\\n{different_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch prefer **clone()** with **detach()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 5., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "tensor([[1., 8., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "another_matrix=matrix.view(1,6).clone().detach()  # detach method remove the tensor from the computational graph\n",
    "another_matrix[0,1]=8 \n",
    "\n",
    "print(f\"{matrix}\\n\\n{another_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `as_tensor()` and `from_numpy()` shares underlying data with original numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor=torch.as_tensor(X_train)\n",
    "X_train.dtype,X_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor=X_train_tensor.float() # lower precision float occupy less memory and are faster to compute\n",
    "X_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment with the tensor\n",
    "dummy_array=np.array([1,2,3])\n",
    "dummy_tensor=torch.as_tensor(dummy_array)\n",
    "dummy_array[1]=0\n",
    "\n",
    "dummy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor()` always make a copy of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_tensor2=torch.tensor(dummy_array)\n",
    "dummy_array[1]=9\n",
    "\n",
    "dummy_tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform tensor to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 9 3]  --->\t<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f'{dummy_tensor.numpy()}  --->\\t{type(dummy_tensor.numpy())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU/GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many GPUs and Which model they are\n",
    "n_cudas=torch.cuda.device_count()\n",
    "for i in range(n_cudas):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2457], dtype=torch.float64)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn tensor into cuda tensor\n",
    "gpu_tensor=torch.as_tensor(X_train).to(device)\n",
    "gpu_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# we need to transform our numpy arrays into tensors and send them to chosen device\n",
    "X_train_tensor=torch.as_tensor(X_train).float().to(device)\n",
    "y_train_tensor=torch.tensor(y_train).float().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.type()` is more useful since it tells us where the tensor is (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "\n",
      "torch.float32\n",
      "\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train_tensor.type()}\\n\\n{X_train_tensor.dtype}\\n\\n{type(X_train_tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a cuda tensor back to numpy array\n",
    "back_to_numpy=X_train_tensor.numpy() # this will throw an error if the tensor is on GPU\n",
    "\n",
    "back_to_numpy=X_train_tensor.cpu().numpy() # this will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mleng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
